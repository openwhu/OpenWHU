# 一、名词解释（每题 5 分，共 30 分）

## 2021 - 2022

### 预训练

预训练（Pretraining）指在机器学习模型应用于特定任务前，借助**大量无标签数据或自监督学习任务**对模型开展初步训练，使其习得**通用的特征表示**。此过程通常不依赖具体任务标签，而是通过挖掘数据的潜在结构与规律，为后续任务提供优质的初始模型。这样，模型在后续下游特定任务训练（即“微调”或 “fine - tuning”）时，能**更快适应**特定任务或数据集。

### 注意力机制

深度学习中的注意力机制（Attention Mechanism）是一种**模仿人类视觉和认知系统的方法**，它允许神经网络在处理输入数据时**集中注意力于相关的部分**。数据中哪些部分比其他部分更重要取决于上下文。这样，模型能够动态地选择关注哪些输入部分，从而提高任务的效果和效率。通常用于序列到序列任务（如机器翻译、文本生成、语音识别等）。

### 词性标注

词性标注（Part - of - Speech Tagging）是对文本中的词语进行语法分析，并为其标注词性标签的过程。词性标签代表词语的语法属性，如动词、名词、形容词等。该过程不仅考虑单词的语法功能，还会结合上下文信息，因为许多单词在不同语境下词性不同。

### 语言模型

语言模型（Language Model, LM）是一种概率模型，用于预测语言中词语序列出现的可能性。其核心任务是基于给定上下文，计算某个词或词序列在该上下文中出现的概率，以此反映语言的结构规律和词语间的相互关系。语言模型广泛应用于语音识别、机器翻译、自动生成文本、拼写纠错等自然语言处理任务。

### 词向量

词向量（Word Embedding）是一种用于表示文本中单词的密集、连续的数字向量形式。它通过数学方式将语言中的单词映射到一个固定维度的向量空间中，使得语义上相似的单词在空间中距离更近，从而便于机器理解和处理语言。常用的将单词表示为词向量的方法有 Word2Vec、Glove 等。

## 2022 - 2023

### 自然语言

自然语言（Natural Language）是人类用于交流的语言，具有丰富的语法、词汇和语义规则，是人类社会的主要沟通工具。它高度灵活且复杂，能表达思想、情感、意图等各类信息。与计算机语言或人工语言不同，自然语言存在模糊性、多义性和上下文依赖性等特点。

### 自然语言处理

自然语言处理是计算机科学与人工智能的一个分支，致力于研究如何让计算机理解、生成和处理人类的自然语言，目标是使机器能像人类一样处理语言信息，实现人与机器的高效交互。自然语言认知和理解是让计算机将输入语言转化为有意义的符号和关系，再按需处理；自然语言生成系统则是把计算机数据转化为自然语言。

### 分词

分词（Word Segmentation）是自然语言处理的基础任务，即将句子、段落、文章等长文本拆分为以字词为单位的数据结构，以方便后续处理分析。分词并非简单的字符分割，还需考虑词语的语义和上下文关系，其准确性直接影响后续自然语言处理任务，如文本分类、情感分析和机器翻译等。

### 实体识别

实体识别（NER）指从文本中识别具有特定意义的实体，并将其分类到预定义的类别中，如人名、地名、机构名、日期等。该任务不仅要识别实体，还要区分不同类型的实体，是信息抽取和文本理解的重要步骤，广泛应用于问答系统、机器翻译、信息检索等领域。

### 循环神经网络

循环神经网络（Recurrent Neural Network, RNN）是一类处理序列数据的神经网络模型，其核心特征是具备循环结构，使得网络在处理当前时刻输入时，能保留并利用前一时刻的状态信息。与传统的前馈神经网络（如多层感知机）不同，RNN 可在网络中留存先前的计算结果，从而处理具有时序关系或上下文依赖的输入数据，能捕捉序列中的时间依赖性，广泛应用于自然语言处理、语音识别、时间序列预测等任务。

### 语言模型（2）

同前文语言模型解释。

### 词向量（2）

同前文词向量解释。

## 2023 - 2024

### 关系抽取

关系抽取（Relation Extraction, RE）旨在从文本中识别并抽取实体之间的语义关系，核心目标是从结构化或非结构化文本中找出一对或多对实体及其相互关系，并转化为机器可理解的形式，以便后续分析或推理。它是信息抽取（IE）任务的重要环节，常用于构建知识图谱、事件抽取等应用，即从一段文本中抽取出（主体，关系，客体）这样的三元组。

### 价值观对齐

价值观对齐（Value Alignment）指确保人工智能（AI）系统的行为、决策和目标与人类的道德、伦理和社会价值观保持一致的过程。其核心目的是让 AI 系统在执行任务时，不仅保证效率和准确性，还遵循人类社会认可的伦理规范和价值准则。

### 词义排歧

词义排歧（Word Sense Disambiguation, WSD）是自然语言处理任务，旨在依据上下文信息确定多义词在特定语境中的准确含义。由于许多词汇在语言中有多个义项，该任务的目标是从句子或文本的上下文中推断出词汇在当前场景下的精确意思。

### 序列到序列（Seq2seq）模型

序列到序列（Seq2Seq）模型是处理序列数据的神经网络架构，能将一个输入序列映射到一个输出序列。常见应用包括机器翻译、文本摘要、语音识别等任务，输入和输出虽都是序列，但长度可不同。该模型通常由编码器（Encoder）和解码器（Decoder）两部分组成。

### 词向量（3）

同前文词向量解释。

### 预训练模型

预训练模型（Pre - trained Model）是在大规模数据集上进行初步训练的深度学习模型。这些模型经训练已获得对某一或多个任务的基本理解，可在此基础上进一步微调（Fine - tuning）以适配具体应用场景或任务。预训练模型的优势在于，训练前就已具备丰富的语义理解或特征表示，能减少对标注数据的需求。

## 名词解释补充题

### 梯度

梯度是标量函数对其输入向量（或矩阵）所有分量的偏导数组成的向量或矩阵，它表示函数在每个变量上的变化率，指向函数增长最快的方向。

### 概率上下文无关句法

概率上下文无关句法通过为文法规则赋予概率值，来表示不同句法结构的生成概率。在 PCFG 中，每个文法规则都有对应的概率，代表该规则在生成语句时的相对可能性，广泛应用于句法分析、语言模型和机器翻译等任务。

### n 元语法模型

n 元语法模型是基于统计的语言模型，用于描述句子中词语间的关系。它假设当前词的出现仅依赖于前面 n - 1 个词，具体通过固定长度的上下文窗口来预测下一个词或词序列。

### 柱搜索

柱搜索是广泛应用于序列生成任务的启发式搜索算法，在每一步搜索中保留最优的多个候选解，而非仅选择单一最优解。它通过维护固定大小的候选集（即“柱宽度”），在搜索过程中考虑多条可能路径，以平衡计算效率和解的质量。与贪心算法相比，柱搜索能探索更多候选路径，避免陷入局部最优解，常用于机器翻译、语音识别等自然语言处理任务。

### subword

Subword（子词）是比单词小、比字符大的语言单位，通常包含词根、前缀、后缀等。例如，英文单词 "unhappiness" 可拆分为子词 "un", "happi", "ness"。这种拆分方式能让模型捕捉词汇的内部结构和语义信息，通过将单词拆分为子词单元，模型可有效处理未登录词（OOV）和稀有词，提升对多样化语言现象的建模能力。

### 指令微调

指令微调是改进大型语言模型（LLMs）的训练方法，通过进一步训练模型，使其能理解并执行人类以自然语言形式给出的指令。其目标是让模型在面对多样化任务时，生成更准确且人类可解释的回答，同时具备更强的泛化能力。

### RLHF

RLHF（基于人类反馈的强化学习）是结合人类反馈和强化学习的机器学习方法。在传统强化学习中，智能体通过与环境交互获取奖励信号，而 RLHF 引入人类反馈（如示范、偏好或评分）来引导智能体学习，广泛应用于任务复杂且难以明确设定奖励的场景，如自然语言处理、机器人控制等。

### 自然语言生成

自然语言生成旨在将结构化或非结构化的数据转化为流畅且符合语言规范的自然语言文本，广泛应用于机器翻译、对话系统、自动摘要、报告生成等领域。

### 越狱攻击

攻击者通过设计特定输入，利用模型的弱点或漏洞，诱导其生成违反伦理或道德约束的文本。例如，使用模糊表达或误导性语句，使模型无法识别潜在的有害内容。

# 二、简答题（每题 10 分，共 40 分）

2021-2022:

1. 举出三个分类任务，并说明应用场景。
   （1）    情感分析（Sentiment Analysis）
   情感分析是指对文本中的情感倾向进行分类，通常将文本分为正面、负面或中性三类。通过对评论、文章或社交媒体上的文本进行分析，判断其中的情感态度。
   应用场景：
   社交媒体监控：品牌和公司可以分析用户在社交平台上的评论，了解公众对产品、服务或事件的情感反应，以便做出及时的调整。
   产品评价分析：电商平台可通过情感分析自动识别客户评价中的情感倾向，帮助商家了解客户的满意度和需求，优化产品和服务。
   （2）    文本分类（Text Classification）
   文本分类是将文本分配到一个或多个类别中。常见的应用包括垃圾邮件检测、新闻分类等。任务目标是根据文本的内容将其自动归类。
   应用场景：
   垃圾邮件过滤：电子邮件系统可以自动分类垃圾邮件和正常邮件，避免用户收到不需要的广告或恶意邮件。
   新闻分类：新闻网站和媒体平台通过文本分类将新闻分为不同的类别（如体育、娱乐、政治等），以便用户快速找到感兴趣的内容。
   （3）    命名实体识别（Named Entity Recognition, NER）
   命名实体识别任务的目标是从文本中识别出具有特定意义的实体，如人名、地名、组织名、日期等，并将这些实体进行分类。
   应用场景： 信息抽取：在法律、医学或财务文档中，NER 可自动抽取重要信息，如公司名、病例信息或合同条款，为专业人士提供支持。
   搜索引擎优化：搜索引擎可以通过 NER 从搜索查询中识别用户关心的实体（如公司、地名），提供更加精准的搜索结果，提高用户体验。

2. 简述 LSTM 和 GRU 的结构，并说明区别
   （1）    LSTM 单元由三个主要门控和一个候选状态组成：遗忘门（Forget Gate）：遗忘门决定丢弃多少信息
   输入门（Input Gate）：控制新的输入信息对当前单元状态的影响输出门（Output Gate）：控制单元状态对隐藏状态的影响
   Cell State：存储长期依赖信息，经过遗忘门和输入门的控制更新。

（2）    GRU 是 LSTM 的简化版本，主要由三个门控组成：
更新门（Update Gate）：决定当前状态有多少信息从上一时刻传递到当前时刻，控制记忆的保留和更新。
重置门（Reset Gate）：决定当前输入信息与前一时刻的隐藏状态结合的程度，控制遗忘的过程。
输出门

（3）    区别：
门控机制：LSTM 使用三个门控（遗忘门、输入门、输出门）和 Cell State，而 GRU 仅使用两个门控（更新门和重置门）。GRU 的结构较为简洁，参数较少。
Cell State：LSTM 具有独立的 Cell State，用于存储长时间依赖信息，而 GRU
通过隐藏状态直接传递信息，不使用单独的 Cell State。
计算效率：由于 GRU 的结构较简单，它在某些任务中计算更为高效，并且参数量较少，因此训练速度可能较快。
LSTM 和 GRU 都通过门控机制来处理长期依赖问题，但 LSTM 具有更复杂的结构，适用于需要细粒度控制的任务，而 GRU 由于其简洁性，在一些任务中能够提供与 LSTM 相似的效果。

3. 简述 CBOW 和 Skip-gram 训练词向量方式的区别。
   （1）    输入与输出的关系：CBOW  模型的输入是上下文词，输出是目标词；而
   Skip-gram 的输入是目标词，输出是上下文词。
   （2）    适用场景：CBOW 适合处理高频词，Skip-gram 更适合低频词的学习。

（3）    计算量：由于 CBOW 是通过多个上下文词来预测一个中心词，因此在训练时通常计算量较小；而 Skip-gram 需要通过一个中心词来预测多个上下文词，因此计算量相对较大。

4. 简述 Bert 和GPT 的结构区别与预训练的区别。
   （1）    结构区别：
   BERT 和 GPT 都基于 Transformer 架构。BERT 使用的是 Transformer 中的 Encoder 部分，强调双向上下文的学习。它通过自注意力机制捕获输入文本的上下文信息，并在每个位置上同时考虑左侧和右侧的上下文。BERT 的输入包括特殊标记[CLS]（用于句子级任务）和[SEP]（用于分隔两个句子）。而 GPT 使用的是 Transformer 中的 Decoder 部分，侧重于单向上下文的建模。GPT 采用自回归模型，从左到右生成文本，每次预测下一个词时，只依赖于之前的上下文信息，因此它的输入是一个连贯的文本序列，没有像 BERT 那样的[CLS]和[SEP]标记。

（2）    预训练区别：
BERT 的预训练任务包括 MLM 和 NSP。在 MLM 任务中，BERT 通过随机遮蔽输入文本中的一些词，并要求模型预测这些被遮蔽的词，从而利用双向上下文学习词汇的语义表示。NSP 任务则训练 BERT 判断两个句子是否在原始文本中相邻。与 BERT 不同，GPT 的预训练任务为 CLM，它通过自回归的方式训练模型，预测文本中每个位置的下一个词。GPT 的目标是根据前面的词生成连贯的文本，

因此它在训练时只考虑单向的上下文信息。

2022-2023:

1. 举出三个分类任务，并说明应用场景。（2）

2. 简述卷积神经网络，循环神经网络，Transformer 模型的特点（区别）
   （1）卷积神经网络（CNN）：
   CNN 通过卷积层提取局部特征，通过池化层降低维度，再通过全连接层输出结果。在 NLP 中，CNN 能够有效捕捉局部模式（如短语或词组），但由于其局部感知能力有限，难以处理长距离的上下文依赖关系。CNN 的优点在于并行计算能力强，计算效率高，尤其适合于局部特征的提取，但它无法有效建模序列中的全局依赖。

3. 循环神经网络（RNN）的特点
   循环神经网络（RNN）设计用于处理序列数据，通过递归结构捕捉时间上的依赖关系。在 NLP 中，RNN 广泛应用于语言建模、机器翻译等任务。RNN的优势在于能够处理变长输入序列，并且能够捕捉到序列中的时间依赖性。然而， RNN 面临梯度消失和梯度爆炸的问题，导致在处理长序列时性能较差，训练速度较慢。此外，由于其递归结构，RNN 无法像 CNN 那样并行处理数据，计算效率较低。

4. Transformer 的特点
   Transformer 是一种基于自注意力机制的模型，能够并行处理序列数据，克服了 RNN 的顺序处理瓶颈。Transformer 通过自注意力机制捕捉序列中每个位置与其他位置的关系，具有出色的全局依赖建模能力。与 CNN 和 RNN 不同， Transformer 不依赖递归或卷积操作，因此能高效并行计算，大大提高了训练速度。Transformer 适合处理长序列，能够有效捕捉长距离依赖，因此在机器翻译、文本生成等任务中表现优异。尽管计算资源消耗较大，尤其在处理长序列时，其强大的建模能力使其在 NLP 领域成为主流模型。

5. 简述 Word2Vec 训练词向量的原理和方法。  
   （1）    Word2Vec 训练词向量的原理
   Word2Vec 是一种通过神经网络模型学习词向量的技术，旨在将词汇映射到一个低维稠密向量空间。其核心思想是基于上下文预测词汇，即通过给定一个上下文（周围词语），来预测目标词的概率分布，或者反过来，通过目标词来预测上下文中的词。通过这种方式，Word2Vec 模型能够捕捉到词与词之间的语义关系。训练过程中，词向量会根据上下文中词汇的共现信息进行更新，使得语义相似的词在向量空间中的距离较近，而语义不同的词的距离较远。

（2）    Word2Vec 的训练方法
Word2Vec 有两种常见的训练方法：CBOW 和 Skip-gram。
① CBOW：该方法通过上下文中的词来预测中心词。即在给定上下文窗口中其他词的条件下，预测目标词。CBOW 适合于小型语料，训练速度较快。
② Skip-gram：与 CBOW 相反，Skip-gram 通过中心词来预测上下文中的词，即给定目标词，预测其周围的上下文词。Skip-gram 对于稀有词效果较好，但训练速度较慢。两种方法最终都会得到每个词的词向量，通过反向传播优化神经网络的参数，使得词向量能够有效地捕捉语义信息。



4. 简述 Transformer 中self-attention 的原理和计算流程  
   (1)    Self-Attention 的原理：
   Self-attention 旨在为输入序列中的每个位置分配一个权重，用以表示该位置与其他所有位置的关联性。通过这一机制，模型能够对每个单词在句子中的上下文进行编码，以捕捉全局依赖关系。Self-attention 的主要目标是计算序列中每个元素的加权表示，其中加权系数由序列中其他元素的相关性决定。
   (2)    Self-Attention 的计算流程：

2023-2024:

1. 举例说明情感分析的过程与应用场景

情感分析的过程通常包括数据预处理、特征提取、模型训练和情感分类几个关键步骤。
（1）    首先，通过数据预处理步骤将原始文本转化为结构化形式，例如去除停用词、标点符号或其他无意义信息，并对文本进行分词或词向量化处理。
（2）    然后，利用自然语言处理模型提取文本的语义特征，捕捉上下文中的情感信息。
（3）    接着，通过训练好的情感分类模型（如基于深度学习的模型）对文本进行分类。
（4）    最终输出情感类别或情感得分，表示文本所传达的情感倾向。

情感分析的应用场景覆盖了多个领域，尤其在商业和社会治理中具有重要价值。在商业领域，情感分析可以帮助企业理解用户对产品、服务或品牌的反馈，从而优化运营策略，改进客户体验。在社交媒体分析中，情感分析用于研究公众对某一事件或话题的态度倾向，为舆论引导和公关决策提供依据。此外，在影视、

音乐等文化领域，情感分析可以帮助创作者了解观众或听众的偏好，为作品内容改进提供参考。

2. 介绍一下 RNN 以及其在 nlp 中的应用

（1）    循环神经网络（RNN）是一种专为处理序列数据设计的神经网络模型，能够捕捉输入序列中的时序依赖关系。其独特之处在于通过隐藏层的循环结构将前一时刻的隐藏状态传递到当前时刻，从而在处理当前输入时结合历史信息。这使得 RNN 特别适合处理时间序列、文本数据等具有顺序特性的任务。然而，由于梯度消失和梯度爆炸问题，RNN 在处理长序列时性能有限，这促使改进模型如 LSTM 和 GRU 的出现，它们通过设计门控机制有效解决了这一问题。
（2）    在自然语言处理（NLP）领域，RNN 被广泛应用于各种需要考虑上下文或顺序关系的任务。例如，在机器翻译中，RNN 能够逐词接收源语言序列并生成目标语言序列，是传统 Seq2Seq 模型的核心组件。在文本生成任务中，RNN可以基于已有的上下文生成连贯的句子。此外，在语音识别、情感分析和问答系统等任务中，RNN 也因其对时间依赖的建模能力而表现出色。尽管近年来被 Transformer 架构取代，RNN 在早期 NLP 发展的过程中起到了重要的推动作用，并为后续模型的设计奠定了基础。

3. 简述 Word2Vec 模型中的两种常见训练方法 CBOW 和Skip-Gram的区别（3）

4. 简述 BERT 的结构与预训练过程
   （1）    BERT 使用的是 Transformer 中的 Encoder 部分，强调双向上下文的学习。它通过自注意力机制捕获输入文本的上下文信息，并在每个位置上同时考虑左侧和右侧的上下文。BERT 的输入包括特殊标记[CLS]（用于句子级任务）和 [SEP]（用于分隔两个句子）。

（2）    BERT 的预训练任务包括 MLM 和 NSP。在 MLM 任务中，BERT 通过随机遮蔽输入文本中的一些词，并要求模型预测这些被遮蔽的词，从而利用双向上下文学习词汇的语义表示。NSP 任务则训练 BERT 判断两个句子是否在原始文本中相邻。

简答题补充：

1. 成分句法和依存句法的区别？
   成分句法分析：将句子分解为若干个成分，每个成分是一个短语或单词，具有独立的语法功能。结果通常以成分语法树表示，树的每个节点代表一个成分，边表示成分之间的语法关系。成分句法树是嵌套结构的树。
   依存句法分析：依存句法分析将句子中的词汇视为节点，边表示词汇之间的依赖关系。每个词汇都有一个中心词，其它词汇作为依赖词与之相连。结果通常以依存语法树表示，其中节点是词汇，边表示词汇之间的依赖关系。依存句法树是多叉树。

2. PCFG 基本问题:给定一个句子W=w_1…w_n 和文法 G，如何快速计算概率P(W|G)?
   用的是内向算法。

3. 依存树的具有什么性质？Projective 的性质是什么？
   依存树是一个用于表示句子中词汇之间依赖关系的结构。依存树是一棵树状结构，根节点通常是句子的谓词或核心动词。每个节点代表句子中的一个词，而边则表示词与词之间的依赖关系。依存树具有以下几个性质：每个词只能依赖一个其他词（即每个词只有一个父节点），并且没有环路，即树是一个无环图。
   如果一棵依存树是不满足 projective 性质的，那么依存树至少有两条边是要相交的，满足 projective 性质的树没有边相交。

4. 如何得到 gold 操作序列来训练分类器？
   ①首先需要明确任务的目标和输入数据的类型
   ②随后通过人工标注、规则生成或自动化标注等方式为每个数据样本分配真实标签。对于序列标注任务（如命名实体识别或动作分类），每个时间步、每个实体或每个位置的标签组成了一个完整的操作序列，这些标签被视为 gold 标准。人工标注是通过专家根据任务需求对原始数据进行详细标注，或者通过规则推断生成标签。这些标注的结果可以直接作为训练数据，供分类器学习使用。
   ③最终，经过处理和格式化后的 gold 操作序列可以作为训练集，输入到分类器中进行训练，从而优化模型的性能。

5. 语言模型可能具有什么问题？有什么解决方案？
   （1）    稀疏问题：在 n 元语法模型中，训练数据只包含有限数量的文本，但语言中可能有非常多的词序列（特别是长序列）。在这种情况下，很多词对或 n 元组
   （例如二元组或三元组）可能从未在训练数据中出现过。由于零频问题，模型可能为这些未见过的 n 元组分配零概率，这会导致模型无法正确处理这些未见过的词序列，影响整体性能。解决方法：
   加一法：每一种情况出现的次数加 1
   Good-Turing 平滑：将已经出现的词的概率进行打折，打折后分出一部分概率给没有出现的词。
   （2）    存储问题：是指在构建 n 元语法模型时，随着 n 的增大，模型需要存储大量的 n 元组，这些 n 元组的数量呈指数级增长，从而导致存储和计算资源的需求迅速增大。解决方案：控制 n-gram 的 n。

6. 神经语言模型和n-gram 语言模型的比较?
   n-gram 语言模型是一种基于概率统计的方法，假设一个词的出现仅与前 n-1个词有关，忽略更远的上下文信息。虽然 n-gram 模型简单,并且在许多任务中表现良好，但其缺点是维度高、稀疏问题严重，并且无法捕捉长距离依赖关系。
   相比之下，神经语言模型通过深度学习技术构建，能够处理更复杂的语言结

构。神经语言模型通常使用 RNN、LSTM 或 Transformer 等架构，能够通过学习上下文中的所有信息来生成词的概率分布。它能够自动学习更丰富的语法和语义关系，克服了 n-gram 模型中的上下文限制，因此具有更好的泛化能力和处理长距离依赖的能力。然而，神经语言模型通常需要大量的数据和计算资源，并且训练时间较长。



7. RNN 具有什么问题？
   （1）    梯度消失问题：梯度消失问题指的是在反向传播过程中，梯度随着时间步的增加变得非常小，导致网络无法有效更新权重，进而无法学习到长序列中的长期依赖关系。每当网络的层数增加时，梯度需要被乘以许多小于 1 的数值，这会导致梯度变得越来越小，最终在网络的深层消失。激活函数的选择也影响梯度消失问题。
   （2）    梯度爆炸问题：梯度爆炸问题指的是在反向传播过程中，梯度随着时间步的增加变得非常大，导致网络的权重更新过度，从而使模型的训练过程不稳定，甚至导致模型无法收敛。当权重矩阵的值过大时，梯度会在反向传播过程中迅速增大。长期依赖的计算中，链式法则会导致梯度不断放大。
   （3）    梯度裁剪：梯度裁剪是指在反向传播过程中，限制梯度的最大值。具体来说，当梯度的范数超过某个阈值时，梯度被缩放，使得其范数不超过该阈值，从而避免梯度爆炸问题。

8. 阅读理解和开放领域的问答的区别？
   阅读理解任务通常要求模型基于一段给定的文本或文章来回答问题。模型需要从提供的上下文中提取相关信息并生成准确的答案。通常是基于文本中明确给出的信息进行回答，答案通常是一个明确的事实或段落中的一部分。
   相比之下，开放领域的问答则没有限制于特定的文本或上下文，而是允许模型在更广泛的信息源中寻找答案。这类任务不仅要求模型能够处理各种来源的信息（如百科全书、新闻、网页等），还要具备较强的知识推理能力和信息整合能力。

三、算法（15 分）
2021-2022：无
2022-2023：无
2023-2024：

1. 自注意力（self-attention）机制，包括公式，字母含义等。（2）

算法题补充：

1. 反向传播算法
   （1）    前向计算: 根据公式构建计算图，计算每个节点的值
   （2）    后向计算: 反向遍历计算图，计算每个节点的梯度
   
   

2. 内向算法
   
   

3. Attention 的几个公式     
   
   
   
   
   
   

# 四、方案设计（每题 15 分）

2021-2022：

1. 现在有一个15000 条中文新闻组成的数据，标注了其中的命名体，但是有些实体存在重叠和嵌入，例如“武汉大学”包含“武汉”这个实体。请设计一个方案进行命名实体识别，要求写出流程图、模块说明、评价指标。
2. 方案设计流程

1.1.    数据预处理

文本清洗：去除新闻文本中的特殊字符、HTML 标签、多余空格等噪声信息。
分词：使用中文分词工具（如 jieba）对新闻文本进行分词处理。
标签转换：将标注的命名实体转换为合适的标签格式，针对重叠和嵌入实体，采用多层 BIO 标注法，例如对于“武汉大学”和“武汉”，可以分别标注为 B-School I-School 和 B-City I-City。
数据集划分：将 15000 条数据按照 70%、15%、15% 的比例划分为训练集、验证集和测试集。

1.2.    实体识别模型设计

选择基于 Transformer 的预训练模型（如 BERT）作为基础，构建命名实体识别模型。

输入层：将分词后的文本转换为词嵌入（包括词向量、位置向量和段向量），并添加特殊标记（如 [CLS] 和 [SEP]）。
Transformer 层：使用预训练的 BERT 模型提取文本的上下文特征。
实体识别层：在 Transformer 层的输出基础上，添加一个全连接层和 Softmax 层，对每个词进行多层 BIO 标签预测。

1.3.    训练与优化

损失函数：使用交叉熵损失函数计算模型预测标签与真实标签之间的差异。
优化器：采用 Adam 优化器更新模型参数。
学习率调度：使用学习率衰减策略，防止过拟合。
训练策略：在训练过程中，使用早停机制，当验证集上的性能不再提升时，停止训练。

1.4.    评价指标

① 精度（Precision）：正确识别出的命名实体数占所有识别实体的比例。

其中，TP 为正确识别的实体数，FP 为错误识别的实体数。

② 召回率（Recall）：正确识别出的命名实体数占所有实际存在的命名实体的比例。

其中，FN 为未能识别的实体数。

③ F1 值（F1-Score）：精度和召回率的调和平均值，常用于综合评估模型性能。

④ 实体边界精度（Entity Boundary Accuracy）：对于重叠实体，评估模型在边界识别上的准确性，确保实体的边界被准确标注。

2. 流程图

以下是命名实体识别过程的流程图：

3. 模块说明

数据预处理模块：负责对文本进行分词、实体标注处理等基础工作，为后续模型训练和预测提供干净的数据。
实体识别模型模块：核心部分，利用深度学习模型（如 BERT、LSTM 等）进行实体识别，处理嵌套和重叠问题。
后处理模块：对模型输出的结果进行进一步处理，合并重叠的实体，避免重复标注。
评价模块：计算精度、召回率、F1 值和实体边界精度等指标，对模型进行评估。

2. 现在有一个 15000 条中文和其英文翻译的数据集。请设计一个方案进行深度学习的机器翻译任务，要求写出流程图、模块说明、评价指

标。

1. 方案设计流程

1.1.    数据预处理与准备

①文本清洗：去除文本中的噪音，如多余的空格、标点符号、HTML 标签等。
②分词：对于中文进行分词，英文按单词分割。中文分词可以使用 jieba 等工具。英文分词可以使用 nltk 或 spacy 等工具。
③数据对齐：确保每一条中文数据都有对应的英文翻译，保持数据的准确性和对齐。
④词汇表构建：构建中文和英文的词汇表，统计每个词的频率，并根据频率构建一个合适大小的词表。对于词汇表中的低频词可以使用 <UNK> 表示。
⑤句子长度限制：设置一个最大句子长度，过滤掉超过该长度的句子。

1.2.    模型设计

选择一个基于深度学习的机器翻译模型结构。常用的模型结构包括 Seq2Seq
和 Transformer 模型。
（1）    Seq2Seq（序列到序列）模型：
基于编码器-解码器架构，使用循环神经网络（RNN）或其变体（如 LSTM或 GRU）作为基本单元。编码器将输入的中文句子编码成一个固定维度的上下文向量，解码器根据这个上下文向量生成对应的英文句子。
（2）    Transformer 模型：
Transformer 架构基于自注意力机制，采用并行化的计算方式，避免了 RNN模型的序列化计算问题，能够更高效地处理长文本。主要包括编码器和解码器两个部分，每个部分由多个自注意力层和前馈神经网络组成。其关键机制是多头自注意力（Multi-Head Attention），能够处理全局信息。
该架构在机器翻译任务中表现优秀，通常用于解决中文到英文等高质量翻译任务。

1.3.    训练与优化

①训练数据：将数据集分为训练集、验证集和测试集（例如 70%训练，15%验证， 15%测试）。
②损失函数：使用交叉熵损失函数（Cross-Entropy Loss）来衡量模型的翻译质量。

③优化器：使用 Adam 优化器或其他优化算法进行训练，以加速模型的收敛。

④学习率调度：根据验证集的性能调整学习率，防止过拟合。

1.4.    后处理与翻译生成

①解码方法：翻译过程中可以采用不同的解码策略：
Beam Search：通过维持多个候选翻译路径，搜索最优翻译，通常能够获得更好的翻译效果。
②输出格式：输出的翻译文本将经过后处理，去除额外的标点符号、空格等，确保翻译结果的自然流畅。

1.5.    评价指标

① BLEU（Bilingual Evaluation Understudy）分数： BLEU 是衡量机器翻译质量的标准指标，计算机器翻译结果与人工参考翻译之间的 n-gram 匹配度。通常用于衡量翻译的流畅度和准确度。
② ROUGE（Recall-Oriented Understudy for Gisting Evaluation）分数： ROUGE
用于评估生成的文本与参考文本的重叠程度，适用于评估机器翻译的召回率。
③ METEOR（Metric for Evaluation of Translation with Explicit ORdering）分数： METEOR 结合了精度和召回率，并且考虑了词形变化和同义词等因素。
④TER（Translation Edit Rate）： TER 评估翻译结果与参考翻译的编辑距离，计算所需的最小编辑操作数。

2. 流程图
   
   

3. 模块说明

①数据预处理模块：负责对输入的中文和英文数据进行清洗、分词处理、词汇表构建等，为模型提供干净且结构化的数据。
②模型设计与训练模块：负责选择合适的深度学习模型架构（如 Seq2Seq 或
Transformer）进行训练，调整超参数，优化模型性能。

③翻译生成与后处理模块：对模型的输出进行翻译生成，采用解码策略（如 Greedy 或 Beam Search），并对翻译结果进行后处理，确保输出符合语法和流畅度要求。
④评价与优化模块：使用标准的机器翻译评价指标（如 BLEU、ROUGE、METEOR
等）对模型的翻译效果进行评估，指导模型的进一步优化。



2022-2023：

1. 现在有一个 15000 条数据产品的评论数据，已经人工标注了情感正负极，请设计一个基于深度学习模型的情感分类方案，要求写出流程图、模块说明、评价指标。

2. 方案设计流程

1.1.    数据预处理与准备

①文本清洗：去除评论中的噪声，如多余的空格、HTML 标签、特殊字符等。

②分词：将中文评论按词语进行切分，英文评论按单词切分。可以使用 jieba（中文）或 nltk/spacy（英文）工具进行分词。
③数据标注：确保数据中每条评论对应着正确的情感标签（正面/负面）。通常，情感标签可以为 1（正面）和 0（负面）。
④词向量化：将评论中的每个词转换为对应的词向量。可以使用预训练的词向量
（如 Word2Vec、GloVe）或者使用模型如 BERT 来生成上下文相关的词向量。

⑤训练集/验证集/测试集划分：将数据集划分为训练集（70%）、验证集（15%）和测试集（15%），确保数据集的多样性和代表性。
1.2.    模型设计

选择适合情感分类的深度学习模型。常用模型包括：

①卷积神经网络（CNN）：CNN 在文本情感分类任务中表现较好，尤其在捕捉局部特征（如情感关键词、短语）的方面。通过卷积层提取特征后，使用池化层压缩信息，最后通过全连接层进行情感分类。
优势：擅长从文本中提取局部特征，适合处理句子级别的情感分类任务。

②长短时记忆网络（LSTM）：LSTM 是一种基于 RNN 的模型，能够有效捕捉文本中的长期依赖关系。对于情感分类任务，LSTM 能够理解评论中情感词语间的顺序和上下文关系。
优势：适合处理序列数据，能够捕捉评论中词语的上下文关系。

③Transformer/BERT：Transformer 架构基于自注意力机制，能够并行处理序列中的每个元素，具有很强的表达能力。BERT 是基于 Transformer 的预训练模型，已经在多个 NLP 任务中取得了优异的表现，尤其适合情感分类任务。
优势：能够捕捉全局信息并处理长文本，BERT 提供了强大的语境理解能力。

1.3.    训练与优化

①损失函数：使用交叉熵损失函数（Cross-Entropy Loss），它是二分类问题中最常用的损失函数，衡量模型输出概率与实际标签之间的差异。
②优化器：使用 Adam 优化器，它是基于自适应学习率的优化算法，能够在训练过程中动态调整学习率，提高收敛速度和精度。
③学习率调度：根据训练集的损失变化动态调整学习率，防止过拟合和加速模型收敛。
1.4.    评价指标

①准确率（Accuracy）：准确率是最常用的评价指标，表示分类正确的样本占总样本的比例。公式：Accuracy = (TP + TN) / (TP + TN + FP + FN)。
②精确率（Precision）：精确率用于衡量模型预测为正面的样本中，实际为正面的比例。公式：Precision = TP / (TP + FP)。
③召回率（Recall）：召回率用于衡量所有实际为正面的样本中，模型预测为正面的比例。公式：Recall = TP / (TP + FN)。
④F1-score：F1-score 是精确率和召回率的调和平均数，综合了二者的优缺点，适用于不平衡数据集。公式：F1 = 2 * (Precision * Recall) / (Precision + Recall)。
⑤AUC（Area Under ROC Curve）：
AUC 表示 ROC 曲线下的面积，越接近 1 代表模型越好。该指标不依赖于具体的分类阈值，适合评估模型在不同阈值下的表现。
1.5.    翻译生成与后处理

①翻译生成：根据模型输出的情感类别，生成对应的预测标签（例如“正面”或“负面”）。
②后处理：检查生成的情感标签是否符合语法规则，确保输出的准确性与合理性。

2. 流程图

以下是情感分类任务的流程图：



3. 模块说明

①数据预处理模块：负责对输入的评论数据进行清洗、分词、词向量化等，为模型提供高质量的输入数据。
②模型设计与训练模块：负责选择和训练深度学习模型（如 CNN、LSTM、 Transformer 等），并调整超参数来优化模型性能。
③翻译生成与后处理模块：对模型的输出情感标签进行后处理，确保输出结果符合情感分类任务的要求。
④评价与优化模块：使用标准的情感分类评价指标（如准确率、精确率、召回率、
F1-score、AUC 等）对模型性能进行评估，并根据评估结果进一步优化模型。

2. 现在有 10 万篇爬取的文档（无标注），1000 条句子（使用BIO 标注了人名、地名实体），设计一个 Transformer 模型，采用预训练和 Fine-Tune 构建一个实体识别系统，要求写出流程图、模块说明、评价指标。
3. 方案设计流程

1.1.    数据预处理

①无标注数据：对于 10 万篇无标注文档，首先进行文本清洗（如去除多余的空格、特殊字符等），然后通过分词工具（如 jieba）将文档切分成词。无标注数据将用于预训练阶段。
②有标注数据：1000 条句子已经进行 BIO 标注，可以用于 Fine-Tune 阶段。BIO标注是指对于每个单词标注其是否是一个实体的开始（B-），内部（I-）或者非实体（O）。
③数据扩充：可以使用无标注数据通过半监督学习或自训练方法扩充标注数据，增强模型的泛化能力。
④数据集划分：将 1000 条 BIO 标注句子划分为训练集（80%）、验证集（10%）和测试集（10%）。

1.2.    模型设计

选择基于 Transformer 的预训练语言模型（如 BERT、RoBERTa、DistilBERT
等），并在其基础上进行 Fine-Tuning，设计实体识别模型。

①输入层：将每个词汇映射为词嵌入（embedding），包括词嵌入（word embedding）、位置嵌入（position embedding）和段落嵌入（segment embedding）。可以使用预 训练的 BERT 模型进行初始化。

②Transformer Encoder：使用 Transformer Encoder 模块，进行多头自注意力机制（Multi-head Attention）和前馈神经网络（Feed-Forward Neural Network）计算。
③输出层：对于每个输入的单词，预测其对应的实体标签（BIO 标注格式）。该层可以是一个全连接层，后接 softmax 层，输出每个单词属于某个实体类别的概率。
1.3.    训练与优化

①损失函数：使用交叉熵损失函数（Cross-Entropy Loss），适用于多分类任务。对于 NER 任务，损失函数计算每个词的 BIO 标签与模型输出之间的差异。
②优化器：使用 Adam 优化器，其在深度学习中表现出较好的性能。

③学习率调度：采用学习率衰减方法，避免训练过程中出现梯度爆炸或过拟合。

④Fine-Tuning 阶段：使用已经在大规模语料上预训练的 BERT 模型，并在标注数据上进行 Fine-Tuning。在 Fine-Tuning 过程中，通常冻结部分低层模型的参数，只训练高层的分类层。
⑤数据增强：可以使用数据增强技术，如对输入的文本进行随机插入、删除、替换等操作，以提高模型的泛化能力。
1.4.    评价指标

在实体识别任务中，常用的评价指标包括：

①精确率（Precision）：精确率是指模型预测为正实体（例如人名、地名）的标签中，实际为正实体的比例。公式：Precision = TP / (TP + FP)。
②召回率（Recall）：召回率是指所有实际为正实体的标签中，模型正确预测为正实体的比例。公式：Recall = TP / (TP + FN)。

③F1-score：F1-score 是精确率和召回率的调和平均数，能够综合考虑精确率和召回率的性能。公式：F1 = 2 * (Precision * Recall) / (Precision + Recall)。
④实体级别准确率（Entity-Level Accuracy）：该指标衡量的是在预测时实体的边界（开始和结束位置）是否完全正确，不仅考虑实体标签是否正确，还需要检查实体的边界是否准确。
⑤准确率（Accuracy）：对于 NER 任务，准确率是指所有词的正确标记比例，公式为：Accuracy = (Correctly Tagged Words) / (Total Words)。
1.5.    流程图

以下是基于 Transformer 的实体识别系统的流程图：



2. 模块说明

①数据预处理模块： 负责对输入的文本数据进行清洗、分词处理，并将已有的
BIO 标注应用到文本上。此外，还需将数据划分为训练集、验证集和测试集。

②预训练阶段： 加载预训练的 BERT 模型（或其他 Transformer 模型），使用无标注的 10 万篇文档进行预训练。该阶段帮助模型学习语言的基本结构和词语的上下文关系。

③Fine-Tuning 阶段： 在已经预训练的模型基础上，使用标注的 1000 条句子进行微调，优化模型在实体识别任务上的性能。
④实体识别模块： 负责对输入文本进行实体识别，输出相应的 BIO 标注结果。

⑤模型评估模块： 计算并输出模型的精确率、召回率、F1-score 等指标，用于衡量模型的性能。
3.    总结

本方案设计了一个基于 Transformer 模型的命名实体识别系统，通过预训练与 Fine-Tune 相结合的方式，利用 10 万篇无标注文档和 1000 条 BIO 标注数据进行训练。模型设计充分考虑了数据预处理、Transformer 架构、优化与评价指标等多个环节，确保实体识别的高效与准确。通过精确率、召回率、F1-score 等指标对模型性能进行综合评估，能够有效提升模型的泛化能力。

2023-2024：

1. 现有 1000 篇没有标注的文档，要求设计 NER 命名实体识别模型
   （要求：流程图，模块说明，模型图，实验设置 等）

2. 方案设计流程

1.1.    数据预处理

①文本清洗：对 1000 篇无标注文档进行文本清洗，去除噪声字符、无关符号和空格等，确保数据质量。
②分词与向量化：使用中文分词工具（如 jieba）对文本进行分词。使用预训练词向量（如 Word2Vec 或 GloVe）将每个词汇映射为词向量。对于无法在词向量中找到的词，可以采用随机初始化或子词分解技术。

③无标注数据生成伪标签：使用现有的 NER 模型（如基于 BERT 的 NER 模型）对无标注数据进行预测，生成伪标签。然后使用这些伪标签作为训练数据进一步微调 NER 模型。
④数据集划分：如果有小量标注数据，使用标注数据进行微调训练；无标注数据通过伪标签进行训练，划分为训练集、验证集和测试集。
1.2.    模型设计

设计一个基于 Transformer（如 BERT）的 NER 模型，具体架构如下：

①输入层：

输入文本序列，并通过分词器对文本进行分词。

将分词后的每个词或子词映射为固定维度的词向量。

②Transformer 层：

使用预训练的 BERT 或类似的 Transformer 模型作为基础模型，通过多头自注意力机制（self-attention）提取输入文本的上下文信息。
模型将通过 Transformer 网络对每个单词进行上下文编码，从而捕捉文本中的语法和语义信息。
③NER 层（输出层）：

将 Transformer 的输出传递给一个全连接层（Feed-Forward Neural Network），用以生成每个单词的实体类别标签（如人名、地名、机构名、其他等）。
输出为每个词的 BIO 标注（B 表示实体的开始，I 表示实体的内部，O 表示非实体）。

1.3.    半监督学习方案

①伪标签生成：使用现有的 NER 模型（如预训练的 BERT 模型）在无标注数据上进行预测，生成伪标签。
②自训练：将伪标签与已有标注数据结合，构建训练集。继续训练 NER 模型，通过自训练方法迭代增强模型的性能。
1.4.    模型训练与优化

①损失函数：使用交叉熵损失函数（Cross-Entropy Loss）进行优化。

②优化器：使用 Adam 优化器进行参数优化，学习率根据训练进程动态调整（如学习率衰减）。
③Fine-Tuning：在预训练的 BERT 模型基础上进行微调，以适应具体任务（NER任务）。通过标注数据和伪标签数据的组合进行 Fine-Tuning。
④正则化：使用 Dropout 和 L2 正则化来防止过拟合。

1.5.    评估与实验设置

（1）    评价指标：

①精确率（Precision）：表示模型预测为实体的标签中，实际为实体的比例。

②召回率（Recall）：表示实际为实体的标签中，模型正确预测的比例。

③F1-score：精确率和召回率的调和平均数，综合衡量模型的性能。

（2）    实验设置：

①数据集划分：使用标注数据的 80%进行训练，10%进行验证，10%用于测试。

②训练轮次（Epochs）：设置模型训练的最大轮数为 10-20 轮，训练过程中通过验证集监控损失和准确率。

③批大小（Batch size）：根据内存限制和数据集大小设置适当的批大小（如 16、 32）。
2.    流程图

以下是基于 Transformer 的命名实体识别（NER）模型的设计流程图：



3. 总结

本设计方案基于Transformer 模型（如 BERT）构建了一个命名实体识别（NER）系统，利用无标注数据和少量标注数据通过半监督学习方法进行实体识别任务。通过数据预处理、模型设计、半监督学习策略、模型训练和优化等步骤，最终完 成实体识别任务。评价指标使用精确率、召回率和 F1-score 进行综合评估，确保模型的准确性和泛化能力。

方案设计补充题：

1. 依存句法分析方案设计（Transition-based）
   （1）    整体方案设计流程图
   
   

（2）    模块说明

2.1    输入句子：接收一段自然语言文本作为输入，开始依存句法分析任务。

2.2    特征提取：从输入句子中提取用于训练和预测的语言学特征。

词汇特征：词的表面形式。
词性标签：每个单词的词性，如名词、动词、形容词等。依存路径：上下文中单词与词汇之间的依存关系。
词向量：使用预训练的词嵌入（如 Word2Vec、GloVe、BERT 等）。语法特征：例如，词的前后词或位置等。
2.3    分类器训练：训练一个分类器来预测句子中每个位置的操作类型。

输入：通过特征提取模块获得的句子特征。
输出：训练分类器输出的操作序列（SHIFT, Left Arc, Right Arc）。
训练数据：使用标注过的依存句法树库（如 Penn Treebank、UD Trees
等）进行训练，句子和对应的操作序列是训练的基础。
分类器模型：可以选择传统机器学习算法（如 SVM、决策树、随机森林）或深度学习方法（如 LSTM、Transformer 等）来训练模型。

2.4    预测操作序列：在测试阶段，根据输入句子的特征，利用训练好的分类器生成一系列的操作序列（SHIFT、Left Arc、Right Arc）。
2.5    解码操作序列：功能：通过应用预测的操作序列，逐步构建出句子的依存语法树。
①SHIFT：将下一个词移入栈中。

②Left Arc：将栈顶词与输入队列中的某个词通过左依赖连接。

③Right Arc：将栈顶词与输入队列中的某个词通过右依赖连接。

2.6    生成依存树：基于操作序列生成完整的依存语法树。

（3）    评价指标

①依存关系正确性 (LAS, Label Accuracy Score)：LAS 关注的是词与其依赖关系和标签是否都正确。

②依存结构正确性 (UAS, Unlabeled Attachment Score)：计算正确依存关系数与所有依存关系的比例，不考虑依存关系标签。

③速度评估（Efficiency）：测量模型处理数据的效率，常用时间消耗、处理速度等指标。单位：每秒处理多少个句子（或文档）。

2. 自然语言生成模型 
   （要求：流程图，模块说明，实验设置等）

一、模块说明

1.1    输入数据预处理与理解模块







等）。

分词：将输入文本切分为词或子词单元，方便后续处理。
去停用词：去除常见但无实际意义的停用词，提高模型处理效率。
编码转换：确保文本数据符合模型的输入要求（如字嵌入、tokenization

1.2    内容规划模块：该模块确定生成文本的内容结构，基于输入或上下文信息选择需呈现的事实、观点、细节等。
1.3    句法规划模块：决定生成文本的句子结构，选择适合的语言风格与语法规则。

1.4    表述生成模块根据规划的内容和句法框架，使用生成式模型（如 GPT、T5、 BART 等）生成流畅的自然语言文本。
1.5    后处理与修正模块：对生成的文本进行后处理，修正语法错误、重复内容等，优化生成的文本流畅性。
1.6    评估与反馈模块（评价指标）：BLEU、ROUGE、BERT 分数等；根据人工评估反馈调整模型参数，优化生成效果。
二、模型训练与优化

2.1    训练过程

极大似然训练（Maximum Likelihood Estimation, MLE）：基于训练数据集，通过最大化训练数据的对数似然函数来训练模型。
Teacher Forcing：在训练阶段，将真实的上一时间步输出作为下一时间步的输入，而不是使用模型自己的预测结果。
2.2    奖励函数（Reward Function）：用于评估生成文本的质量，常见的奖励包括文本流畅度、语法正确性等。

2.3    解决暴露偏差问题

Scheduled Sampling：在训练过程中，根据一定概率在真实词汇和模型预测词汇之间进行选择。
Dataset Aggregation：将模型生成的文本加入到训练集中，以缓解暴露
偏差

三、系统评价与反馈

3.1    内容重叠指标

（1）    BLEU、ROUGE、METEOR：这些 N-gram 重叠指标衡量生成文本与参考文本之间的相似度。
（2）    PYRAMID、SPICE、SPIDEr：语义重叠指标，考虑生成文本的语义信息。

3.2    基于模型的指标

BERT 打分：利用预训练的 BERT 词嵌入，计算生成文本和参考文本的语义相似度。
3.3    人工评估：流畅度、一致性、事实性、常识性、风格/格式四、实验设置
4.1    数据集：

训练数据：使用大规模语料库（如 OpenWebText、WikiText 等）进行训
练。
评估数据：使用标准评估数据集（如 SQuAD、CNN/DailyMail 等）。



4.2    优化器：使用 Adam 或AdamW 优化器，结合学习率调度（如 CosineAnnealing）。



4.3    训练设置：

预训练：使用大规模文本数据进行模型预训练。
微调：根据任务需求对模型进行微调。

3. 大语言模型设计
   现需要设计一个大语言模型系统，包含提示学习、自然语言生成、问答等功能。（要求：流程图，模块说明，实验设置等）
   一、模块说明

1.1    输入处理模块：文本的预处理，包括分词、去停用词、转换为标准化的输入格式等。
1.2    提示学习模块：生成适当的提示引导语言模型完成特定任务。根据任务要求，可以采用零-shot 学习、few-shot 学习或利用任务-specific 提示进行训练。
1.3    自然语言生成模块（NLG）：根据输入文本生成目标文本，涵盖新闻生成、摘要生成等。
1.4    问答模块（QA）：从文本或知识库中提取答案，支持基于文档的问答和开放域问答。
1.5    输出处理模块：对生成的文本进行后处理，确保语法正确和文本连贯。二、实验设置
2.1    数据集：

文本生成：使用开放数据集如 OpenWebText、WikiText 等进行训练。问答任务：使用标准问答数据集，如 SQuAD、TriviaQA 等。

评估数据集：根据任务要求，收集相应的评估数据集，或使用通用领域数据集进行初步评估。
2.2    训练环境

硬件：采用 GPU（如 NVIDIA A100 或 V100）加速训练过程。框架：使用 PyTorch、TensorFlow 等深度学习框架。
优化器：选择 Adam 或 AdamW 优化器，使用学习率调度策略。

2.3    训练设置

预训练：利用大规模语料库进行模型预训练。
微调：根据特定任务微调模型参数，使用少量领域特定数据。

2.4    评价指标

自然语言生成：

BLEU：衡量生成文本与参考文本的相似度。 ROUGE：衡量生成摘要与参考摘要的重合度。 Perplexity：衡量生成模型的难度，值越低越好。
问答任务：

EM（Exact Match）：预测答案与真实答案的完全一致度。
F1 Score：结合准确率与召回率，衡量答案的准确性和完整性。

### 情感分类方案设计

#### 1. 流程图

```plaintext
+-------------------+       +---------------+       +---------------+
| 数据预处理        |  -->  | 数据集划分    |  -->  | 特征提取      |
| (清洗、分词)      |       | (训练/验证/测试)|       | (词向量/位置向量)|
+-------------------+       +---------------+       +---------------+
                                                       |
                                                       v
+-------------+       +-------------------+       +---------------+
| 模型构建     |  -->  | 训练              |  -->  | 微调(Fine-tune) |
| (选择架构)  |       | (损失函数、优化器)|       | (增量训练)     |
+-------------+       +-------------------+       +---------------+
                                                       |
                                                       v
+-------------+       +-------------+       +---------------+
| 测试        |  -->  | 评估        |  -->  | 输出结果      |
| (输入/输出) |       | (精确率、召回率、F1) |       | (模型部署)    |
+-------------+       +-------------+       +---------------+
```

---

#### 2. 模块说明

**模块1：数据预处理**

1. **数据清洗**
   - 去除HTML标签、特殊字符、重复数据
   - 处理缺失值（删除或补充）
   - 修正编码问题
2. **分词**
   - 使用NLTK/Jieba等工具进行分词
   - 去除停用词（如"的"、"了"等）

**模块2：数据集划分**

- 按8:1:1比例划分训练集/验证集/测试集
- 确保正负样本比例均衡（如正负比为3:2，需按比例划分）

**模块3：特征提取**

1. **词向量**
   - 使用预训练词向量（如GloVe、Word2Vec、BERT-base）
   - 词嵌入维度：100/200/300
2. **位置向量**
   - 绝对位置编码：`PE(pos, 2i) = sin(pos/10000^(2i/d_model))`
   - 相对位置编码：`PE(pos_i - pos_j)`

**模块4：模型选择与构建**

1. **模型架构**
   
   - **Transformer架构**：
     
     ```
     Input -> Embedding Layer -> Position Encoding -> 
     Multi-head Attention -> Feed Forward -> Output Layer
     ```
   
   - **LSTM架构**：
     
     ```
     Input -> Embedding Layer -> 
     LSTM Layer (双向) -> Attention Layer -> Dense Layer
     ```
   
   - **公式**：
     
     - LSTM单元：
       
       ```
       f_t = σ(W_f[h_{t-1}, x_t] + b_f)
       i_t = σ(W_i[h_{t-1}, x_t] + b_i)
       o_t = σ(W_o[h_{t-1}, x_t] + b_o)
       C_t = f_t * C_{t-1} + i_t * tanh(W_c[h_{t-1}, x_t] + b_c)
       h_t = o_t * tanh(C_t)
       ```
     
     - Transformer自注意力：
       
       ```
       Attention(Q,K,V) = softmax(QK^T/√d_k)V
       ```

**模块5：训练**

1. **数据类型**：仅使用标注数据（15000条）

2. **预训练**：使用预训练词向量初始化嵌入层

3. **损失函数**：交叉熵损失
   
   ```
   Loss = -Σ[y_i log(p_i) + (1-y_i) log(1-p_i)]
   ```

4. **优化器**：Adam优化器
   
   ```
   θ = θ - η * m_t / (sqrt(v_t) + ε)
   ```

**模块6：微调(Fine-tune)**

- 冻结预训练层，仅训练最后一层
- 逐步解冻部分中间层进行训练

**模块7：测试**

- 输入：预处理后的评论文本

- 输出：情感类别（正/负）

- 推理公式：
  
  ```
  y_pred = argmax(softmax(W * h + b))
  ```

**模块8：评估**

1. **精确率(Precision)**
   
   ```
   Precision = TP / (TP + FP)
   ```

2. **召回率(Recall)**
   
   ```
   Recall = TP / (TP + FN)
   ```

3. **F1 Score**
   
   ```
   F1 = 2 * (Precision * Recall) / (Precision + Recall)
   ```

---

#### 3. 技术选型建议

1. **工具框架**：PyTorch/TensorFlow
2. **预训练模型**：BERT-base/Nezha/ERNIE
3. **数据增强**：同义词替换、EDA技术
4. **计算资源**：建议使用GPU加速（如RTX 3090/T4）

#### 4. 预期效果

1. 验证集F1 Score ≥ 0.85
2. 测试集精确率 ≥ 0.88
3. 召回率 ≥ 0.87

该方案可根据实际数据分布和硬件资源进一步优化调整。
